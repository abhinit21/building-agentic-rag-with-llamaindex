{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Router Engine",
   "id": "5e6461d87001e862"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Router Engine Diagram](assets/router-engine.png)]",
   "id": "d62d397b1740a44a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ],
   "id": "259876ee1ee16181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "a875bef9eddbb491"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "999719423b3dad99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "from llama_index.core import SimpleDirectoryReader"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load documents\n",
    "documents = SimpleDirectoryReader(input_files=['assets/metagpt.pdf']).load_data()"
   ],
   "id": "7218ad8a0ccd44cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define LLM and Embedding model",
   "id": "f8bb31bd94058708"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ],
   "id": "7925224fe90eb6fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model='gpt-3.5-turbo')\n",
    "Settings.embed_model = OpenAIEmbedding(model='text-embedding-ada-002')"
   ],
   "id": "519117c74d203faf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Summary Index and Vector Index",
   "id": "ca6661d7b7006308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ],
   "id": "7c52137530dd1b01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Query Engines",
   "id": "9738741c76bcebad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode='tree_summarize',\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ],
   "id": "243e172193e5f5b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        'Useful for summarization questions related to MetaGPT'\n",
    "    )\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        'Useful for retrieving specific context from MetaGPT'\n",
    "    )\n",
    ")"
   ],
   "id": "891f3c7062a308d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Router Query Engine",
   "id": "ab526e80b72ebc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "b7783d34f30a8a02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = query_engine.query('Summarize the document')\n",
    "\n",
    "print(str(response))"
   ],
   "id": "fc19b4910e47a480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(response.source_nodes)",
   "id": "481216d966dc05dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = query_engine.query('How do agents share information with other agents ?')\n",
    "\n",
    "print(str(response))"
   ],
   "id": "e57a35b5589ecfb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(response.source_nodes)",
   "id": "c96b85ba23b569e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Given a file path create a router query engine",
   "id": "f8c3cfd7419ab91f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import SimpleDirectoryReader, SummaryIndex, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "def get_router_query_engine(file_path: str, llm = None, embed_model = None):\n",
    "    \"\"\"Get router query engine\"\"\"\n",
    "    llm = llm or OpenAI(model='gpt-3.5-turbo')\n",
    "    embed_model = embed_model or OpenAIEmbedding(model='text-embedding-ada-002')\n",
    "    \n",
    "    # Load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    \n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    \n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    \n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode='tree_summarize',\n",
    "        use_async=True,\n",
    "        llm=llm\n",
    "    )\n",
    "    vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            'Useful for summarization questions related to MetaGPT'\n",
    "        )\n",
    "    )\n",
    "    vector_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=vector_query_engine,\n",
    "        description=(\n",
    "            'Useful for retrieving specific context from MetaGPT'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    query_engine = RouterQueryEngine(\n",
    "        selector=LLMSingleSelector.from_defaults(),\n",
    "        query_engine_tools=[\n",
    "            summary_tool,\n",
    "            vector_tool\n",
    "        ],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return query_engine"
   ],
   "id": "c1c22cae0d09436a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "query_engine = get_router_query_engine('assets/metagpt.pdf')",
   "id": "9bd13e2f490163ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = query_engine.query('Explain ablation study results')\n",
    "\n",
    "print(str(response))"
   ],
   "id": "94e58f1b031fc5df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

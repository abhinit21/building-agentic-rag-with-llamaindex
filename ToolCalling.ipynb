{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tool Calling",
   "id": "d95db5057fc8a1c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "de12358a1fce63ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define a Simple Tool",
   "id": "e9d564117591db4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ],
   "id": "184db4a733cebda8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool],\n",
    "    \"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ],
   "id": "242b971ab9b6641c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Auto-Retrieval Tool",
   "id": "76a58e6a93ed7259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=['assets/metagpt.pdf']).load_data()"
   ],
   "id": "5c113f222563ed35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ],
   "id": "83d3cfb4d022d9ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(nodes[0].get_content(metadata_mode='all'))",
   "id": "a15c6bc77d3692ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)"
   ],
   "id": "5a38c6c86477ea9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {'key': 'page_label', 'value': '2'}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    'What are some high-level results of MetaGPT?'\n",
    ")"
   ],
   "id": "b4e21ea994194d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(str(response))",
   "id": "74ba3dc3ff11fa93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "id": "f06e989f7a1f80c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define a Auto-Retrival Tool",
   "id": "3b96949f04e39087"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "def vector_query(query: str, page_numbers: List[str]) -> str:\n",
    "    metadata_dicts = [\n",
    "        {'key': 'page_label', 'value': p} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name='vector_tool',\n",
    "    fn=vector_query\n",
    ")"
   ],
   "id": "25f01c81d9f8caad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool],\n",
    "    'What are the high-level results of MetaGPT on page 2?',\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "91c2c3a00ac6c819"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "id": "e1e5fc15670d36d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add a Summary Tool",
   "id": "be623871114424a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode='tree_summary',\n",
    "    use_async=True\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name='summary_tool',\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        'Useful if you want to get a summary of MetaGPT'\n",
    "    )\n",
    ")"
   ],
   "id": "e6b0c6e9aabeb9b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    'What are the MetaGPT comparisons with ChatDev described on page 8?',\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "93b7a47242e32bfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "id": "578238cf430b0c01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    'What is a summary of the paper?',\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "68a55360c9fde75c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
